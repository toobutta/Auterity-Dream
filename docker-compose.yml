version: '3.8'

services:
  # Shared Infrastructure Services
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-workflow_engine}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-unified-db.sql:/docker-entrypoint-initdb.d/init-unified-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # AutoMatrix Services (Existing)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      SECRET_KEY: ${SECRET_KEY}
      RELAYCORE_URL: ${RELAYCORE_URL:-http://relaycore:3001}
      NEUROWEAVER_BACKEND_URL: ${NEUROWEAVER_BACKEND_URL:-http://neuroweaver-backend:8001}
      CORS_ORIGINS: ${CORS_ORIGINS}
      DEBUG: ${DEBUG:-true}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      MINIO_ENDPOINT: ${MINIO_ENDPOINT:-minio:9000}
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY:-minioadmin123}
      QDRANT_HOST: ${QDRANT_HOST:-qdrant}
      QDRANT_PORT: ${QDRANT_PORT:-6333}
      ELASTICSEARCH_HOST: ${ELASTICSEARCH_HOST:-elasticsearch:9200}
      EVIDENTLY_URL: ${EVIDENTLY_URL:-http://evidently:8085}
      TWILIO_ACCOUNT_SID: ${TWILIO_ACCOUNT_SID}
      TWILIO_AUTH_TOKEN: ${TWILIO_AUTH_TOKEN}
      TWILIO_PHONE_NUMBER: ${TWILIO_PHONE_NUMBER}
      SENDGRID_API_KEY: ${SENDGRID_API_KEY}
      MAILGUN_API_KEY: ${MAILGUN_API_KEY}
      MAILGUN_DOMAIN: ${MAILGUN_DOMAIN}
      WHATSAPP_ACCESS_TOKEN: ${WHATSAPP_ACCESS_TOKEN}
      WHATSAPP_PHONE_NUMBER_ID: ${WHATSAPP_PHONE_NUMBER_ID}
      BROWSERLESS_URL: ${BROWSERLESS_URL:-http://puppeteer:3000}
      KONG_ADMIN_URL: ${KONG_ADMIN_URL:-http://kong:8001}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      VITE_API_URL: ${EXTERNAL_AUTMATRIX_BACKEND_URL:-http://localhost:8000}
      VITE_RELAYCORE_URL: ${EXTERNAL_RELAYCORE_URL:-http://localhost:3001}
      VITE_NEUROWEAVER_URL: ${EXTERNAL_NEUROWEAVER_FRONTEND_URL:-http://localhost:3002}
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # RelayCore Service (AI Routing Hub)
  relaycore:
    build:
      context: ./systems/relaycore
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      CLAUDE_API_KEY: ${CLAUDE_API_KEY}
      SECRET_KEY: ${SECRET_KEY}
      NEUROWEAVER_BACKEND_URL: ${NEUROWEAVER_BACKEND_URL:-http://neuroweaver-backend:8001}
      DEFAULT_MODEL: ${RELAYCORE_DEFAULT_MODEL:-gpt-3.5-turbo}
      COST_THRESHOLD: ${RELAYCORE_COST_THRESHOLD:-10.00}
      ENABLE_STEERING: ${RELAYCORE_ENABLE_STEERING:-true}
      DEBUG: ${DEBUG:-true}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./systems/relaycore:/app
      - /app/node_modules
    command: npm run dev
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # NeuroWeaver Backend (Model Specialization)
  neuroweaver-backend:
    build:
      context: ./systems/neuroweaver/backend
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      SECRET_KEY: ${SECRET_KEY}
      RELAYCORE_URL: ${RELAYCORE_URL:-http://relaycore:3001}
      MODEL_STORAGE_PATH: ${NEUROWEAVER_MODEL_STORAGE_PATH:-/app/models}
      TRAINING_ENABLED: ${NEUROWEAVER_TRAINING_ENABLED:-true}
      AUTO_DEPLOY: ${NEUROWEAVER_AUTO_DEPLOY:-false}
      DEBUG: ${DEBUG:-true}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./systems/neuroweaver/backend:/app
      - neuroweaver_models:/app/models
    command: uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # NeuroWeaver Frontend (Model Management UI)
  neuroweaver-frontend:
    build:
      context: ./systems/neuroweaver/frontend
      dockerfile: Dockerfile
    ports:
      - "3002:3002"
    environment:
      NEXT_PUBLIC_API_URL: ${EXTERNAL_NEUROWEAVER_BACKEND_URL:-http://localhost:8001}
      NEXT_PUBLIC_RELAYCORE_URL: ${EXTERNAL_RELAYCORE_URL:-http://localhost:3001}
      NEXT_PUBLIC_AUTMATRIX_URL: ${EXTERNAL_AUTMATRIX_FRONTEND_URL:-http://localhost:3000}
    volumes:
      - ./systems/neuroweaver/frontend:/app
      - /app/node_modules
      - /app/.next
    command: npm run dev
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # Monitoring Services
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - ai-platform

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3003:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager:/etc/alertmanager
    networks:
      - ai-platform

  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      COLLECTOR_OTLP_ENABLED: true
    networks:
      - ai-platform

  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
    networks:
      - ai-platform

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    environment:
      DATA_SOURCE_NAME: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      - postgres
    networks:
      - ai-platform

  redis-exporter:
    image: oliver006/redis_exporter:latest
    environment:
      REDIS_ADDR: redis://redis:6379
    ports:
      - "9121:9121"
    depends_on:
      - redis
    networks:
      - ai-platform

  # Object Storage
  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # Local LLM Hosting
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai-platform

  # Search and Analytics
  elasticsearch:
    image: elasticsearch:8.11.0
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      discovery.type: single-node
      xpack.security.enabled: false
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # ML Monitoring
  evidently:
    image: evidently/evidently-service:latest
    ports:
      - "8085:8085"
    environment:
      EVIDENTLY_SERVICE_PORT: 8085
      EVIDENTLY_SERVICE_HOST: 0.0.0.0
    volumes:
      - evidently_data:/app/data
    networks:
      - ai-platform

  # Web Automation
  playwright:
    image: mcr.microsoft.com/playwright:latest
    ports:
      - "3001:3001"
    environment:
      PLAYWRIGHT_BROWSERS_PATH: /ms-playwright
    volumes:
      - playwright_data:/ms-playwright
    networks:
      - ai-platform
    command: npx playwright install && tail -f /dev/null

  puppeteer:
    image: browserless/chrome:latest
    ports:
      - "3000:3000"
    environment:
      MAX_CONCURRENT_SESSIONS: 10
      CONNECTION_TIMEOUT: 60000
    networks:
      - ai-platform

  # API Gateway
  kong:
    image: kong:latest
    ports:
      - "8000:8000"
      - "8443:8443"
      - "8001:8001"
      - "8444:8444"
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /kong/declarative/kong.yml
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
    volumes:
      - ./kong:/kong/declarative
    networks:
      - ai-platform

  kibana:
    image: kibana:8.11.0
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      XPACK_SECURITY_ENABLED: false
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # Log Aggregation
  loki:
    image: grafana/loki:latest
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki:/etc/loki
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  promtail:
    image: grafana/promtail:latest
    volumes:
      - ./monitoring/promtail:/etc/promtail
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - ai-platform

  # Secrets Management
  vault:
    image: hashicorp/vault:latest
    ports:
      - "8200:8200"
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_ROOT_TOKEN:-dev-token}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
    volumes:
      - vault_data:/vault/data
      - ./vault/config:/vault/config
    cap_add:
      - IPC_LOCK
    command: vault server -dev -dev-listen-address=0.0.0.0:8200
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics
      - "8889:8889"   # Prometheus exporter metrics
    volumes:
      - ./monitoring/otel:/etc/otelcol-contrib
    command: ["--config=/etc/otelcol-contrib/otel-collector.yaml"]
    depends_on:
      - jaeger
      - prometheus
      - loki
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:13133/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  # Event Streaming
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - ai-platform

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    volumes:
      - kafka_data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      - kafka
    networks:
      - ai-platform

  # Task Queue
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      CELERY_BROKER_URL: ${REDIS_URL:-redis://redis:6379/0}
      CELERY_RESULT_BACKEND: ${REDIS_URL:-redis://redis:6379/0}
    depends_on:
      - postgres
      - redis
    volumes:
      - ./backend:/app
    command: celery -A app.celery_app worker --loglevel=info
    networks:
      - ai-platform

  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      CELERY_BROKER_URL: ${REDIS_URL:-redis://redis:6379/0}
      CELERY_RESULT_BACKEND: ${REDIS_URL:-redis://redis:6379/0}
    depends_on:
      - postgres
      - redis
    volumes:
      - ./backend:/app
    command: celery -A app.celery_app beat --loglevel=info
    networks:
      - ai-platform

  # ML Experiment Tracking
  mlflow:
    image: python:3.11-slim
    ports:
      - "5000:5000"
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-workflow_engine}
      MLFLOW_DEFAULT_ARTIFACT_ROOT: s3://mlflow-artifacts
      AWS_ACCESS_KEY_ID: ${MINIO_ACCESS_KEY:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_SECRET_KEY:-minioadmin123}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    volumes:
      - mlflow_data:/mlflow
    depends_on:
      - postgres
      - minio
    command: >
      bash -c "pip install mlflow psycopg2-binary boto3 &&
               mlflow server --host 0.0.0.0 --port 5000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ai-platform

volumes:
  postgres_data:
  redis_data:
  grafana_data:
  prometheus_data:
  neuroweaver_models:
  minio_data:
  qdrant_data:
  ollama_data:
  elasticsearch_data:
  evidently_data:
  playwright_data:
  loki_data:
  vault_data:
  kafka_data:
  zookeeper_data:
  zookeeper_logs:
  mlflow_data:

networks:
  ai-platform:
    driver: bridge