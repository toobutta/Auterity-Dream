# Core dependencies for vLLM service
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
redis==5.0.1
torch==2.1.0
transformers==4.35.0
accelerate==0.24.0
tokenizers==0.15.0

# vLLM for high-throughput inference (optional - auto-installed if not present)
# vllm==0.4.0

# Additional utilities
numpy==1.24.3
aiohttp==3.9.1
python-multipart==0.0.6
python-dotenv==1.0.0

# GPU support (optional)
# vllm[cuda]==0.4.0

# Development dependencies
pytest==7.4.3
pytest-asyncio==0.21.1
black==23.11.0
flake8==6.1.0
mypy==1.7.1
