# Comprehensive AI Model Configuration for Auterity Error-IQ
# Supports multiple AI providers and local model hosting
models:
  # ==================================================
  # OPENAI MODELS
  # ==================================================
  - name: gpt-4o
    provider: openai
    model_family: gpt-4
    max_tokens: 128000
    cost_per_token: 0.000005
    input_cost_per_token: 0.000005
    output_cost_per_token: 0.000015
    capabilities:
      - text
      - chat
      - function_calling
      - reasoning
      - vision
      - multimodal
    context_window: 128000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Most advanced GPT-4 model with vision capabilities"

  - name: gpt-4o-mini
    provider: openai
    model_family: gpt-4
    max_tokens: 128000
    cost_per_token: 0.00000015
    input_cost_per_token: 0.00000015
    output_cost_per_token: 0.0000006
    capabilities:
      - text
      - chat
      - function_calling
      - reasoning
    context_window: 128000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Cost-effective GPT-4 model for most tasks"

  - name: gpt-4-turbo
    provider: openai
    model_family: gpt-4
    max_tokens: 128000
    cost_per_token: 0.00001
    input_cost_per_token: 0.00001
    output_cost_per_token: 0.00003
    capabilities:
      - text
      - chat
      - function_calling
      - reasoning
    context_window: 128000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "High-performance GPT-4 model"

  - name: gpt-4
    provider: openai
    model_family: gpt-4
    max_tokens: 8192
    cost_per_token: 0.00003
    input_cost_per_token: 0.00003
    output_cost_per_token: 0.00006
    capabilities:
      - text
      - chat
      - function_calling
      - reasoning
    context_window: 8192
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Original GPT-4 model with proven reliability"

  - name: gpt-3.5-turbo
    provider: openai
    model_family: gpt-3.5
    max_tokens: 16385
    cost_per_token: 0.0000015
    input_cost_per_token: 0.0000015
    output_cost_per_token: 0.000002
    capabilities:
      - text
      - chat
      - function_calling
    context_window: 16385
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Fast and cost-effective for most conversational tasks"

  # ==================================================
  # ANTHROPIC MODELS
  # ==================================================
  - name: claude-3-5-sonnet-20241022
    provider: anthropic
    model_family: claude-3
    max_tokens: 200000
    cost_per_token: 0.000003
    input_cost_per_token: 0.000003
    output_cost_per_token: 0.000015
    capabilities:
      - text
      - chat
      - reasoning
      - long_context
      - vision
      - multimodal
    context_window: 200000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Most intelligent Claude model with vision"

  - name: claude-3-opus-20240229
    provider: anthropic
    model_family: claude-3
    max_tokens: 200000
    cost_per_token: 0.000015
    input_cost_per_token: 0.000015
    output_cost_per_token: 0.000075
    capabilities:
      - text
      - chat
      - reasoning
      - long_context
      - vision
      - multimodal
    context_window: 200000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Most capable Claude model for complex tasks"

  - name: claude-3-sonnet-20240229
    provider: anthropic
    model_family: claude-3
    max_tokens: 200000
    cost_per_token: 0.000003
    input_cost_per_token: 0.000003
    output_cost_per_token: 0.000015
    capabilities:
      - text
      - chat
      - reasoning
      - long_context
      - vision
      - multimodal
    context_window: 200000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Balanced performance and cost for most tasks"

  - name: claude-3-haiku-20240307
    provider: anthropic
    model_family: claude-3
    max_tokens: 200000
    cost_per_token: 0.00000025
    input_cost_per_token: 0.00000025
    output_cost_per_token: 0.00000125
    capabilities:
      - text
      - chat
      - reasoning
      - long_context
    context_window: 200000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Fast and cost-effective for lightweight tasks"

  # ==================================================
  # NOVITA AI MODELS (200+ models available)
  # ==================================================
  - name: novita-llama-2-70b-chat
    provider: novita
    model_family: llama-2
    max_tokens: 4096
    cost_per_token: 0.000001
    input_cost_per_token: 0.000001
    output_cost_per_token: 0.000002
    capabilities:
      - text
      - chat
      - function_calling
    context_window: 4096
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Llama 2 70B via Novita AI cloud infrastructure"

  - name: novita-mistral-7b-instruct
    provider: novita
    model_family: mistral
    max_tokens: 8192
    cost_per_token: 0.0000005
    input_cost_per_token: 0.0000005
    output_cost_per_token: 0.000001
    capabilities:
      - text
      - chat
      - code
    context_window: 8192
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Mistral 7B Instruct via Novita AI"

  - name: novita-stable-diffusion-xl
    provider: novita
    model_family: stable-diffusion
    max_images: 1
    cost_per_image: 0.05
    input_cost_per_request: 0.05
    output_cost_per_image: 0.05
    capabilities:
      - image
      - generation
      - text-to-image
    max_prompt_length: 77
    supports_streaming: false
    supports_function_calling: false
    is_available: true
    description: "Stable Diffusion XL for high-quality image generation"  - name: novita-whisper-large-v3
    provider: novita
    model_family: whisper
    max_audio_duration: 1800  # 30 minutes
    cost_per_minute: 0.006
    input_cost_per_minute: 0.006
    output_cost_per_minute: 0.012
    capabilities:
      - audio
      - transcription
      - translation
    max_audio_length: 1800
    supports_streaming: false
    supports_function_calling: false
    is_available: true
    description: "Whisper Large V3 for advanced speech recognition"  # ==================================================
  # VLLM LOCAL MODELS
  # ==================================================
  - name: vllm-meta-llama/Llama-2-7b-chat-hf
    provider: vllm
    model_family: llama-2
    endpoint: http://localhost:8001
    max_tokens: 4096
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - local
    context_window: 4096
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Llama 2 7B running locally via vLLM"

  - name: vllm-meta-llama/Llama-2-13b-chat-hf
    provider: vllm
    model_family: llama-2
    endpoint: http://localhost:8001
    max_tokens: 4096
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - local
    context_window: 4096
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Llama 2 13B running locally via vLLM"

  - name: vllm-meta-llama/Llama-2-70b-chat-hf
    provider: vllm
    model_family: llama-2
    endpoint: http://localhost:8001
    max_tokens: 4096
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - local
    context_window: 4096
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Llama 2 70B running locally via vLLM"

  - name: vllm-mistralai/Mistral-7B-Instruct-v0.1
    provider: vllm
    model_family: mistral
    endpoint: http://localhost:8001
    max_tokens: 8192
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - code
      - local
    context_window: 8192
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Mistral 7B Instruct running locally via vLLM"

  # ==================================================
  # HUGGING FACE MODELS
  # ==================================================
  - name: hf-microsoft/DialoGPT-medium
    provider: huggingface
    model_family: dialogpt
    endpoint: https://api-inference.huggingface.co
    max_tokens: 1024
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - conversational
    context_window: 1024
    supports_streaming: false
    supports_function_calling: false
    is_available: true
    description: "DialoGPT for conversational AI via Hugging Face"

  - name: hf-deepset/roberta-base-squad2
    provider: huggingface
    model_family: roberta
    endpoint: https://api-inference.huggingface.co
    max_tokens: 384
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - question-answering
      - nlp
    context_window: 384
    supports_streaming: false
    supports_function_calling: false
    is_available: true
    description: "RoBERTa for question answering via Hugging Face"

  - name: hf-distilbert-base-uncased-finetuned-sst-2-english
    provider: huggingface
    model_family: distilbert
    endpoint: https://api-inference.huggingface.co
    max_tokens: 512
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - sentiment-analysis
      - classification
    context_window: 512
    supports_streaming: false
    supports_function_calling: false
    is_available: true
    description: "DistilBERT for sentiment analysis via Hugging Face"

  # ==================================================
  # OLLAMA LOCAL MODELS
  # ==================================================
  - name: llama2:7b
    provider: ollama
    model_family: llama-2
    endpoint: http://localhost:11434
    max_tokens: 4096
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - local
    context_window: 4096
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Llama 2 7B via Ollama local deployment"

  - name: llama2:13b
    provider: ollama
    model_family: llama-2
    endpoint: http://localhost:11434
    max_tokens: 4096
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - local
    context_window: 4096
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Llama 2 13B via Ollama local deployment"

  - name: mistral:7b
    provider: ollama
    model_family: mistral
    endpoint: http://localhost:11434
    max_tokens: 8192
    cost_per_token: 0.0
    input_cost_per_token: 0.0
    output_cost_per_token: 0.0
    capabilities:
      - text
      - chat
      - code
      - local
    context_window: 8192
    supports_streaming: true
    supports_function_calling: false
    is_available: true
    description: "Mistral 7B via Ollama local deployment"

  # ==================================================
  # GOOGLE MODELS
  # ==================================================
  - name: gemini-pro
    provider: google
    model_family: gemini
    max_tokens: 32768
    cost_per_token: 0.0000005
    input_cost_per_token: 0.0000005
    output_cost_per_token: 0.0000015
    capabilities:
      - text
      - chat
      - reasoning
      - multimodal
      - vision
    context_window: 32768
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Gemini Pro multimodal model from Google"

  - name: gemini-pro-vision
    provider: google
    model_family: gemini
    max_tokens: 16384
    cost_per_token: 0.0000005
    input_cost_per_token: 0.0000005
    output_cost_per_token: 0.0000015
    capabilities:
      - text
      - vision
      - multimodal
      - image-analysis
    context_window: 16384
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Gemini Pro Vision for image and text understanding"

  # ==================================================
  # COHERE MODELS
  # ==================================================
  - name: command-r-plus
    provider: cohere
    model_family: command-r
    max_tokens: 128000
    cost_per_token: 0.000003
    input_cost_per_token: 0.000003
    output_cost_per_token: 0.000015
    capabilities:
      - text
      - chat
      - reasoning
      - long_context
      - tool_use
    context_window: 128000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Command R+ for advanced reasoning and tool use"

  - name: command-r
    provider: cohere
    model_family: command-r
    max_tokens: 128000
    cost_per_token: 0.0000015
    input_cost_per_token: 0.0000015
    output_cost_per_token: 0.000006
    capabilities:
      - text
      - chat
      - reasoning
      - tool_use
    context_window: 128000
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "Command R for efficient reasoning and tool use"

  # ==================================================
  # AZURE OPENAI MODELS
  # ==================================================
  - name: azure-gpt-4
    provider: azure
    model_family: gpt-4
    max_tokens: 8192
    cost_per_token: 0.00003
    input_cost_per_token: 0.00003
    output_cost_per_token: 0.00006
    capabilities:
      - text
      - chat
      - function_calling
      - reasoning
    context_window: 8192
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "GPT-4 via Azure OpenAI Service"

  - name: azure-gpt-35-turbo
    provider: azure
    model_family: gpt-3.5
    max_tokens: 4096
    cost_per_token: 0.000002
    input_cost_per_token: 0.000002
    output_cost_per_token: 0.000002
    capabilities:
      - text
      - chat
      - function_calling
    context_window: 4096
    supports_streaming: true
    supports_function_calling: true
    is_available: true
    description: "GPT-3.5 Turbo via Azure OpenAI Service"
