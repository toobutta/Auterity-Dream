version: '3.8'

# UNIFIED AUTERITY DEPLOYMENT - ALL SERVICES
services:
  # API Gateway
  kong:
    image: kong:latest
    environment:
      - KONG_DATABASE=off
      - KONG_DECLARATIVE_CONFIG=/kong/kong.yml
      - KONG_ADMIN_LISTEN=0.0.0.0:8001
    volumes:
      - ./kong/kong.yml:/kong/kong.yml
    ports:
      - "8000:8000"
      - "8001:8001"
    restart: unless-stopped

  # Core Services
  backend:
    build: ./backend
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/auterity
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=amqp://auterity:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - VAULT_URL=http://vault:8200
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - WHATSAPP_ACCESS_TOKEN=${WHATSAPP_ACCESS_TOKEN}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
      - VAULT_TOKEN=${VAULT_TOKEN}
      - GRAFANA_PASSWORD=${GRAFANA_PASSWORD}
      - BROWSERLESS_URL=http://puppeteer:3000
      - PUPPETEER_TIMEOUT=30000
      - SMTP_HOST=mailhog
      - SMTP_PORT=1025
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_DEFAULT_CHANNEL=#alerts
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-admin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-auterity123}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      kafka:
        condition: service_healthy
      vault:
        condition: service_started
      puppeteer:
        condition: service_healthy
      mailhog:
        condition: service_healthy
    ports:
      - "8080:8000"
    restart: unless-stopped

  frontend:
    build: ./frontend
    environment:
      - VITE_API_URL=http://localhost:8080
    ports:
      - "3002:80"
    restart: unless-stopped

  # Databases
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Message Queue
  rabbitmq:
    image: rabbitmq:3-management-alpine
    environment:
      - RABBITMQ_DEFAULT_USER=auterity
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Event Streaming
  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    ports:
      - "2181:2181"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Secrets Management
  vault:
    image: vault:latest
    environment:
      - VAULT_DEV_ROOT_TOKEN_ID=${VAULT_TOKEN}
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
    volumes:
      - vault_data:/vault/data
    ports:
      - "8200:8200"
    cap_add:
      - IPC_LOCK
    restart: unless-stopped

  # ML Tracking
  mlflow:
    build:
      context: ./mlflow
      dockerfile: Dockerfile
    command: >
      mlflow server --host 0.0.0.0 --port 5000
      --backend-store-uri postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/mlflow
      --default-artifact-root /mlflow/artifacts
    volumes:
      - mlflow_data:/mlflow/artifacts
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "5000:5000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Vector Database
  weaviate:
    image: semitechnologies/weaviate:latest
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=false
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
      - DEFAULT_VECTORIZER_MODULE=text2vec-openai
      - ENABLE_MODULES=text2vec-openai
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - weaviate_data:/var/lib/weaviate
    ports:
      - "8081:8080"
    restart: unless-stopped

  # Task Workers
  celery-worker:
    build: ./backend
    command: celery -A app.celery_app worker --loglevel=info
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/auterity
      - CELERY_BROKER_URL=amqp://auterity:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - RABBITMQ_PASSWORD=${RABBITMQ_PASSWORD}
    depends_on:
      - postgres
      - redis
      - rabbitmq
    restart: unless-stopped
    deploy:
      replicas: 2

  # Monitoring Stack - Enhanced Prometheus
  prometheus:
    image: prom/prometheus:latest
    environment:
      - PROMETHEUS_OPTS=--config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/etc/prometheus/console_libraries --web.console.templates=/etc/prometheus/consoles --web.enable-lifecycle --web.enable-admin-api
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - ./monitoring/prometheus/alerts:/etc/prometheus/alerts:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.external-url=http://localhost:9090'
      - '--log.level=info'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M

  # Enhanced Grafana with Advanced Features
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_SECURITY_ADMIN_USER=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource,grafana-worldmap-panel,grafana-piechart-panel,redis-datasource,marcusolsson-json-datasource
      - GF_FEATURE_TOGGLES_ENABLE=ngalert
      - GF_UNIFIED_ALERTING_ENABLED=true
      - GF_ALERTING_ENABLED=false
      - GF_RENDERING_SERVER_URL=http://renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://grafana:3000/
      - GF_LOG_FILTERS=rendering:debug
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/provisioning/dashboards/auterity-overview.json
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_SMTP_ENABLED=true
      - GF_SMTP_HOST=mailhog:1025
      - GF_SMTP_FROM_ADDRESS=grafana@auterity.local
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/plugins:/var/lib/grafana/plugins
    ports:
      - "3001:3000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - prometheus
      - loki
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "16686:16686"
    restart: unless-stopped

  # Loki Log Aggregation - Enhanced
  loki:
    image: grafana/loki:latest
    environment:
      - LOKI_CONFIG_FILE=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki/local-config.yaml:/etc/loki/local-config.yaml:ro
      - ./monitoring/loki/rules:/etc/loki/rules:ro
      - loki_data:/loki
    ports:
      - "3100:3100"
      - "9096:9096"  # gRPC
    command:
      - '-config.file=/etc/loki/local-config.yaml'
      - '-target=all'
      - '-server.http-listen-port=3100'
      - '-server.grpc-listen-port=9096'
      - '-log.level=info'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M

  # Missing Services - Phase 1 Implementation

  # Puppeteer Browser Automation - Enhanced
  puppeteer:
    image: browserless/chrome:latest
    environment:
      - CONCURRENT=10
      - TOKEN=${PUPPETEER_TOKEN:-auterity-secure-token-2025}
      - WORKSPACE_EXPIRE_DAYS=1
      - PREBOOT_CHROME=true
      - ENABLE_DEBUG_VIEWER=true
      - ENABLE_CORS=true
      - ENABLE_XVFB=true
      - MAX_CONCURRENT_SESSIONS=10
      - SESSION_TIMEOUT=300000
      - ENABLE_STEALTH=true
      - FUNCTION_BUILT_INS=url,json,pdf,screenshot,stats
      - WORKSPACE_DELETE_EXPIRED=true
      - METRICS_JSON_PATH=/workspace/metrics.json
      - ENABLE_API_GET=true
      - ENABLE_API_POST=true
      - DOWNLOAD_PATH=/workspace/downloads
    ports:
      - "3000:3000"
      - "3001:3001"  # Debug viewer
    volumes:
      - puppeteer_workspace:/workspace
      - ./monitoring/puppeteer:/var/log/puppeteer
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/pressure"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'

  # SMTP Email Service - Enhanced Development & Testing
  mailhog:
    image: mailhog/mailhog:latest
    environment:
      - MH_STORAGE=maildir
      - MH_MAILDIR_PATH=/maildir
      - MH_UI_BIND_ADDR=0.0.0.0:8025
      - MH_API_BIND_ADDR=0.0.0.0:8025
      - MH_SMTP_BIND_ADDR=0.0.0.0:1025
      - MH_HOSTNAME=mailhog.auterity.local
      - MH_AUTH_FILE=/etc/mailhog/auth
      - MH_OUTGOING_SMTP_SERVER=smtp.gmail.com:587
      - MH_CORS_ORIGIN=http://localhost:3000,http://localhost:8080
    ports:
      - "1025:1025"  # SMTP
      - "8025:8025"  # Web UI & API
    volumes:
      - mailhog_data:/maildir
      - ./config/mailhog:/etc/mailhog
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:8025"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # Alertmanager - Enhanced Alert Management
  alertmanager:
    image: prom/alertmanager:latest
    environment:
      - ALERTMANAGER_OPTS=--config.file=/etc/alertmanager/alertmanager.yml --storage.path=/alertmanager --web.external-url=http://localhost:9093 --web.enable-lifecycle --log.level=info
    ports:
      - "9093:9093"
      - "9094:9094"  # Cluster port
    volumes:
      - ./monitoring/alertmanager:/etc/alertmanager
      - alertmanager_data:/alertmanager
      - ./monitoring/alertmanager/templates:/etc/alertmanager/templates
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--log.level=info'
      - '--cluster.listen-address=0.0.0.0:9094'
      - '--cluster.advertise-address=alertmanager:9094'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

  # Node Exporter - Enhanced System Metrics
  node-exporter:
    image: prom/node-exporter:latest
    environment:
      - NODE_ID={{.Node.ID}}
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /etc/hostname:/etc/nodename:ro
      - /etc/localtime:/etc/localtime:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netdev.device-exclude=^(veth.*|docker.*|br-.*|lo)$$'
      - '--collector.diskstats.ignored-devices=^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\d+n\\d+p)\\d+$$'
      - '--collector.textfile.directory=/var/lib/node_exporter/textfile_collector'
      - '--collector.systemd'
      - '--collector.processes'
      - '--collector.interrupts'
      - '--collector.tcpstat'
      - '--web.listen-address=:9100'
      - '--web.telemetry-path=/metrics'
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # Redis Exporter - Enhanced Redis Metrics
  redis-exporter:
    image: oliver006/redis_exporter:latest
    environment:
      - REDIS_ADDR=redis://redis:6379
      - REDIS_PASSWORD=
      - REDIS_EXPORTER_CHECK_KEYS=*
      - REDIS_EXPORTER_CHECK_SINGLE_KEYS=db0:key1,db0:key2
      - REDIS_EXPORTER_COUNT_KEYS=*
      - REDIS_EXPORTER_LOG_FORMAT=json
      - REDIS_EXPORTER_DEBUG=false
      - REDIS_EXPORTER_WEB_LISTEN_ADDRESS=:9121
      - REDIS_EXPORTER_WEB_TELEMETRY_PATH=/metrics
    ports:
      - "9121:9121"
    depends_on:
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9121/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # Postgres Exporter - Enhanced Database Metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    environment:
      - DATA_SOURCE_NAME=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/auterity?sslmode=disable
      - PG_EXPORTER_EXTEND_QUERY_PATH=/etc/postgres_exporter/queries.yaml
      - PG_EXPORTER_DISABLE_DEFAULT_METRICS=false
      - PG_EXPORTER_AUTO_DISCOVER_DATABASES=true
      - PG_EXPORTER_EXCLUDE_DATABASES=template0,template1
      - PG_EXPORTER_WEB_LISTEN_ADDRESS=:9187
      - PG_EXPORTER_WEB_TELEMETRY_PATH=/metrics
      - PG_EXPORTER_LOG_LEVEL=info
    ports:
      - "9187:9187"
    volumes:
      - ./monitoring/postgres-exporter:/etc/postgres_exporter:ro
    depends_on:
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9187/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.1'

  # Promtail Log Collector - Enhanced with Advanced Processing
  promtail:
    image: grafana/promtail:latest
    environment:
      - HOSTNAME={{.Node.Hostname}}
    volumes:
      - ./monitoring/promtail:/etc/promtail:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - promtail_positions:/tmp/positions
    command:
      - '-config.file=/etc/promtail/config.yml'
      - '-server.http-listen-port=9080'
      - '-server.grpc-listen-port=9095'
      - '-client.url=http://loki:3100/loki/api/v1/push'
      - '-log.level=info'
      - '-config.expand-env=true'
    ports:
      - "9080:9080"  # HTTP
      - "9095:9095"  # gRPC
    depends_on:
      - loki
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9080/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # MinIO Object Storage - Enhanced S3-Compatible Storage
  minio:
    image: minio/minio:latest
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-auterity-secure-2025}
      - MINIO_BROWSER_REDIRECT_URL=http://localhost:9001
      - MINIO_SERVER_URL=http://localhost:9000
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_PROMETHEUS_URL=http://prometheus:9090
      - MINIO_PROMETHEUS_JOB_ID=minio
      - MINIO_API_SELECT_PARQUET=on
      - MINIO_API_TRANSITION_WORKERS=100
      - MINIO_API_REPLICATION_WORKERS=100
      - MINIO_SCANNER_SPEED=fastest
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    volumes:
      - minio_data:/data
      - ./config/minio:/root/.minio
    command: server /data --console-address ":9001" --address ":9000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M

  # Nginx Load Balancer - Enhanced with Advanced Features
  nginx:
    image: nginx:alpine
    environment:
      - NGINX_ENVSUBST_TEMPLATE_DIR=/etc/nginx/templates
      - NGINX_ENVSUBST_OUTPUT_DIR=/etc/nginx/conf.d
      - BACKEND_HOST=backend
      - BACKEND_PORT=8000
      - FRONTEND_HOST=frontend
      - FRONTEND_PORT=80
      - GRAFANA_HOST=grafana
      - GRAFANA_PORT=3000
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Health/stats
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/templates:/etc/nginx/templates:ro
      - nginx_logs:/var/log/nginx
      - nginx_cache:/var/cache/nginx
    depends_on:
      - backend
      - frontend
      - grafana
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 128M

volumes:
  postgres_data:
  redis_data:
  rabbitmq_data:
  vault_data:
  mlflow_data:
  weaviate_data:
  prometheus_data:
  grafana_data:
  loki_data:
  alertmanager_data:
  minio_data:
  puppeteer_workspace:
  mailhog_data:
  nginx_logs:
  nginx_cache:
  promtail_positions:
