/**
 * Enterprise Orchestrator for Auterity Error-IQ
 * Unified management of all enterprise-grade AI and workflow services
 * Phase 3: Enterprise Features Integration
 */

import { temporalService, TemporalWorkflow } from './TemporalService';
import { weightsAndBiasesService } from './WeightsAndBiasesService';
import { postmanPostbotService } from './PostmanPostbotService';
import { testSigmaService } from './TestSigmaService';
import { novitaAIService, NovitaRequest, NovitaBatchRequest } from './NovitaAIService';
import { unifiedAIOrchestrator } from '../langchain/UnifiedAIOrchestrator';
import { z } from "zod";

// Types for enterprise orchestration
export interface EnterpriseWorkflowRequest {
  name: string;
  type: 'ai-processing' | 'testing' | 'monitoring' | 'deployment' | 'validation';
  priority: 'low' | 'medium' | 'high' | 'critical';
  services: string[];
  input: any;
  options?: {
    timeout?: number;
    retries?: number;
    monitoring?: boolean;
    testing?: boolean;
    costOptimization?: boolean;
  };
}

export interface EnterpriseWorkflowResult {
  workflowId: string;
  status: 'running' | 'completed' | 'failed';
  results: Record<string, any>;
  metrics: {
    duration: number;
    cost: number;
    successRate: number;
    servicesUsed: string[];
  };
  monitoring?: {
    experimentId?: string;
    testSuiteId?: string;
    alerts: any[];
  };
  timestamp: Date;
}

export interface EnterpriseHealthStatus {
  overall: 'healthy' | 'degraded' | 'unhealthy';
  services: {
    temporal: any;
    wandb: any;
    postman: any;
    testSigma: any;
    novita: any;
    aiOrchestrator: any;
  };
  metrics: {
    activeWorkflows: number;
    totalCost: number;
    averageLatency: number;
    successRate: number;
  };
}

export interface EnterpriseAnalytics {
  timeframe: 'hour' | 'day' | 'week' | 'month';
  summary: {
    totalWorkflows: number;
    successfulWorkflows: number;
    failedWorkflows: number;
    totalCost: number;
    averageLatency: number;
    serviceUsage: Record<string, number>;
  };
  trends: {
    costOverTime: Array<{ timestamp: Date; cost: number }>;
    performanceOverTime: Array<{ timestamp: Date; latency: number; successRate: number }>;
    serviceUsageOverTime: Array<{ timestamp: Date; services: Record<string, number> }>;
  };
  recommendations: string[];
}

export class EnterpriseOrchestrator {
  private activeWorkflows: Map<string, EnterpriseWorkflowResult> = new Map();
  private workflowHistory: EnterpriseWorkflowResult[] = [];

  constructor() {
    this.initializeEnterpriseServices();
  }

  /**
   * Initialize all enterprise services
   */
  private async initializeEnterpriseServices(): Promise<void> {
    try {
      console.log('Initializing Enterprise Orchestrator...');

      // All services are already initialized as singletons
      // This method can be used for any cross-service initialization

      console.log('Enterprise Orchestrator initialized successfully');
    } catch (error) {
      console.error('Failed to initialize enterprise services:', error);
    }
  }

  /**
   * Execute enterprise workflow
   */
  async executeEnterpriseWorkflow(request: EnterpriseWorkflowRequest): Promise<EnterpriseWorkflowResult> {
    try {
      const workflowId = `ewf_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      const startTime = Date.now();

      console.log(`Executing enterprise workflow: ${workflowId} (${request.name})`);

      // Create result tracking
      const result: EnterpriseWorkflowResult = {
        workflowId,
        status: 'running',
        results: {},
        metrics: {
          duration: 0,
          cost: 0,
          successRate: 0,
          servicesUsed: request.services
        },
        monitoring: {
          alerts: []
        },
        timestamp: new Date()
      };

      this.activeWorkflows.set(workflowId, result);

      // Start monitoring if requested
      let experimentId: string | undefined;
      if (request.options?.monitoring) {
        experimentId = await this.startWorkflowMonitoring(workflowId, request);
        result.monitoring!.experimentId = experimentId;
      }

      // Execute workflow based on type
      const workflowResults = await this.executeWorkflowByType(request);

      // Update results
      result.results = workflowResults;
      result.status = 'completed';
      result.metrics.duration = Date.now() - startTime;
      result.metrics.successRate = 100; // Assume success for now

      // Run testing if requested
      if (request.options?.testing) {
        const testResults = await this.runWorkflowTesting(workflowId, request, workflowResults);
        result.monitoring!.testSuiteId = testResults.testSuiteId;
      }

      // Clean up monitoring
      if (experimentId) {
        await this.completeWorkflowMonitoring(experimentId, result);
      }

      // Move to history
      this.workflowHistory.push(result);
      this.activeWorkflows.delete(workflowId);

      console.log(`Enterprise workflow ${workflowId} completed successfully`);
      return result;

    } catch (error) {
      console.error(`Enterprise workflow execution failed:`, error);

      // Update failed result
      const failedResult: EnterpriseWorkflowResult = {
        workflowId: `failed_${Date.now()}`,
        status: 'failed',
        results: { error: (error as Error).message },
        metrics: {
          duration: Date.now() - Date.now(),
          cost: 0,
          successRate: 0,
          servicesUsed: request.services
        },
        monitoring: {
          alerts: [{
            type: 'error',
            message: (error as Error).message,
            timestamp: new Date()
          }]
        },
        timestamp: new Date()
      };

      return failedResult;
    }
  }

  /**
   * Execute workflow based on type
   */
  private async executeWorkflowByType(request: EnterpriseWorkflowRequest): Promise<Record<string, any>> {
    const results: Record<string, any> = {};

    switch (request.type) {
      case 'ai-processing':
        results.ai = await this.executeAIProcessingWorkflow(request);
        break;

      case 'testing':
        results.testing = await this.executeTestingWorkflow(request);
        break;

      case 'monitoring':
        results.monitoring = await this.executeMonitoringWorkflow(request);
        break;

      case 'deployment':
        results.deployment = await this.executeDeploymentWorkflow(request);
        break;

      case 'validation':
        results.validation = await this.executeValidationWorkflow(request);
        break;

      default:
        throw new Error(`Unsupported workflow type: ${request.type}`);
    }

    return results;
  }

  /**
   * Execute AI processing workflow
   */
  private async executeAIProcessingWorkflow(request: EnterpriseWorkflowRequest): Promise<any> {
    const results: any = {};

    // Use Temporal for workflow orchestration
    if (request.services.includes('temporal')) {
      const workflowId = await temporalService.startWorkflow(
        request.name,
        'ai-processing',
        request.input,
        {
          priority: request.priority,
          timeout: request.options?.timeout || 3600
        }
      );
      results.temporalWorkflowId = workflowId;
    }

    // Use Novita AI for model processing
    if (request.services.includes('novita')) {
      const novitaRequest: NovitaRequest = {
        model: 'llama-2-7b-chat', // Default model
        input: request.input,
        parameters: {
          temperature: 0.7,
          maxTokens: 1000
        }
      };
      results.novita = await novitaAIService.executeRequest(novitaRequest);
    }

    // Use unified AI orchestrator
    if (request.services.includes('ai-orchestrator')) {
      results.orchestrator = await unifiedAIOrchestrator.orchestrateTask({
        task: 'text-generation',
        input: request.input,
        preferences: {
          costPriority: request.options?.costOptimization ? 'high' : 'medium'
        }
      });
    }

    return results;
  }

  /**
   * Execute testing workflow
   */
  private async executeTestingWorkflow(request: EnterpriseWorkflowRequest): Promise<any> {
    const results: any = {};

    // Create test suite
    const suiteId = `test_suite_${Date.now()}`;
    await testSigmaService.createTestSuite({
      name: `${request.name} Test Suite`,
      description: `Automated testing for ${request.name}`,
      testCases: ['ai-model-response-validation', 'api-validation'], // Predefined test IDs
      environment: 'default-local'
    });

    // Execute test suite
    const suiteResult = await testSigmaService.executeTestSuite(suiteId);
    results.testSuite = suiteResult;

    // Run API tests using Postman Postbot
    if (request.services.includes('postman')) {
      const testId = await postmanPostbotService.createTest({
        name: `${request.name} API Test`,
        endpoint: '/api/v1/health', // Default health check
        method: 'GET',
        headers: {},
        expectedStatus: 200,
        timeout: 5000,
        retries: 2,
        tags: ['enterprise', 'api'],
        environment: 'default'
      });

      const testResult = await postmanPostbotService.runTest(testId);
      results.apiTest = testResult;
    }

    return results;
  }

  /**
   * Execute monitoring workflow
   */
  private async executeMonitoringWorkflow(request: EnterpriseWorkflowRequest): Promise<any> {
    const results: any = {};

    // Create monitoring project
    const projectId = await weightsAndBiasesService.createProject({
      name: `enterprise-${request.name}`,
      description: `Enterprise monitoring for ${request.name}`,
      owner: 'system',
      settings: {
        visibility: 'private',
        allowGuests: false,
        retentionDays: 90
      }
    });

    // Start experiment
    const experimentId = await weightsAndBiasesService.startExperiment(
      request.name,
      projectId,
      {
        description: `Enterprise workflow monitoring for ${request.name}`,
        tags: ['enterprise', 'monitoring'],
        user: 'system'
      }
    );

    results.projectId = projectId;
    results.experimentId = experimentId;

    // Log initial metrics
    await weightsAndBiasesService.logMetrics(experimentId, {
      workflow_start: 1,
      services_count: request.services.length,
      priority: request.priority === 'critical' ? 4 : request.priority === 'high' ? 3 : request.priority === 'medium' ? 2 : 1
    });

    return results;
  }

  /**
   * Execute deployment workflow
   */
  private async executeDeploymentWorkflow(request: EnterpriseWorkflowRequest): Promise<any> {
    const results: any = {};

    // Use Temporal for deployment orchestration
    const workflowId = await temporalService.startWorkflow(
      `${request.name} Deployment`,
      'ai-processing',
      request.input,
      {
        priority: 'high',
        timeout: 7200 // 2 hours for deployment
      }
    );

    results.deploymentWorkflowId = workflowId;

    // Monitor deployment
    const projectId = await weightsAndBiasesService.createProject({
      name: `deployment-${request.name}`,
      description: `Deployment monitoring for ${request.name}`,
      owner: 'system',
      settings: {
        visibility: 'private',
        allowGuests: false,
        retentionDays: 30
      }
    });

    results.monitoringProjectId = projectId;

    return results;
  }

  /**
   * Execute validation workflow
   */
  private async executeValidationWorkflow(request: EnterpriseWorkflowRequest): Promise<any> {
    const results: any = {};

    // Run comprehensive validation tests
    const testSuite = await testSigmaService.createTestSuite({
      name: `${request.name} Validation`,
      description: `Comprehensive validation for ${request.name}`,
      testCases: ['ai-model-response-validation', 'workflow-canvas-ui-test'],
      environment: 'default-local'
    });

    const testResult = await testSigmaService.executeTestSuite(testSuite);
    results.validationTests = testResult;

    // Validate with multiple AI models
    const validationResults = await this.validateWithMultipleModels(request.input);
    results.aiValidation = validationResults;

    return results;
  }

  /**
   * Start workflow monitoring
   */
  private async startWorkflowMonitoring(workflowId: string, request: EnterpriseWorkflowRequest): Promise<string> {
    const projectId = await weightsAndBiasesService.createProject({
      name: `workflow-${workflowId}`,
      description: `Monitoring for workflow ${workflowId}`,
      owner: 'system',
      settings: {
        visibility: 'private',
        allowGuests: false,
        retentionDays: 30
      }
    });

    const experimentId = await weightsAndBiasesService.startExperiment(
      request.name,
      projectId,
      {
        description: `Workflow execution monitoring`,
        tags: ['workflow', 'monitoring', request.type],
        parameters: {
          services: request.services.join(','),
          priority: request.priority,
          timeout: request.options?.timeout
        }
      }
    );

    return experimentId;
  }

  /**
   * Complete workflow monitoring
   */
  private async completeWorkflowMonitoring(experimentId: string, result: EnterpriseWorkflowResult): Promise<void> {
    await weightsAndBiasesService.logMetrics(experimentId, {
      workflow_duration: result.metrics.duration,
      workflow_cost: result.metrics.cost,
      workflow_success: result.status === 'completed' ? 1 : 0,
      services_used: result.metrics.servicesUsed.length
    });

    await weightsAndBiasesService.completeExperiment(experimentId, {
      status: result.status,
      metrics: result.metrics,
      services: result.metrics.servicesUsed
    });
  }

  /**
   * Run workflow testing
   */
  private async runWorkflowTesting(workflowId: string, request: EnterpriseWorkflowRequest, workflowResults: any): Promise<any> {
    const suiteId = await testSigmaService.createTestSuite({
      name: `Workflow ${workflowId} Testing`,
      description: `Automated testing for workflow execution`,
      testCases: ['ai-model-response-validation'], // Simplified for demo
      environment: 'default-local'
    });

    const testResult = await testSigmaService.executeTestSuite(suiteId);

    return {
      testSuiteId: suiteId,
      results: testResult
    };
  }

  /**
   * Validate with multiple AI models
   */
  private async validateWithMultipleModels(input: any): Promise<any> {
    const models = ['llama-2-7b-chat', 'stable-diffusion-xl'];
    const validationResults: any[] = [];

    for (const model of models) {
      try {
        const request: NovitaRequest = {
          model,
          input,
          parameters: {
            temperature: 0.3,
            maxTokens: 500
          }
        };

        const result = await novitaAIService.executeRequest(request);
        validationResults.push({
          model,
          success: true,
          result: result.output,
          cost: result.usage.cost
        });
      } catch (error) {
        validationResults.push({
          model,
          success: false,
          error: (error as Error).message
        });
      }
    }

    return validationResults;
  }

  /**
   * Get enterprise health status
   */
  getHealthStatus(): EnterpriseHealthStatus {
    const temporalHealth = temporalService.getMetrics();
    const wandbHealth = weightsAndBiasesService.getHealthStatus();
    const postmanHealth = postmanPostbotService.getTestStatistics();
    const testSigmaHealth = testSigmaService.getTestStatistics();
    const novitaHealth = novitaAIService.getHealthStatus();
    const aiOrchestratorHealth = unifiedAIOrchestrator.getHealthStatus();

    // Determine overall health
    let overall: 'healthy' | 'degraded' | 'unhealthy' = 'healthy';

    if (!wandbHealth.initialized || !novitaHealth.apiKeyConfigured) {
      overall = 'degraded';
    }

    if (temporalHealth.activeWorkflows === 0 && testSigmaHealth.totalTestCases === 0) {
      overall = 'unhealthy';
    }

    const metrics = {
      activeWorkflows: temporalHealth.activeWorkflows,
      totalCost: novitaHealth.totalCost + (aiOrchestratorHealth.litellm?.costByModel ? Object.values(aiOrchestratorHealth.litellm.costByModel).reduce((a: number, b: number) => a + b, 0) : 0),
      averageLatency: novitaHealth.averageLatency,
      successRate: (temporalHealth.successRate + testSigmaHealth.averageSuccessRate) / 2
    };

    return {
      overall,
      services: {
        temporal: temporalHealth,
        wandb: wandbHealth,
        postman: postmanHealth,
        testSigma: testSigmaHealth,
        novita: novitaHealth,
        aiOrchestrator: aiOrchestratorHealth
      },
      metrics
    };
  }

  /**
   * Generate enterprise analytics
   */
  async generateAnalytics(timeframe: 'hour' | 'day' | 'week' | 'month' = 'week'): Promise<EnterpriseAnalytics> {
    try {
      // Filter workflow history by timeframe
      const cutoffTime = this.getCutoffTime(timeframe);
      const timeframeWorkflows = this.workflowHistory.filter(w => w.timestamp >= cutoffTime);

      // Calculate summary metrics
      const totalWorkflows = timeframeWorkflows.length;
      const successfulWorkflows = timeframeWorkflows.filter(w => w.status === 'completed').length;
      const failedWorkflows = timeframeWorkflows.filter(w => w.status === 'failed').length;
      const totalCost = timeframeWorkflows.reduce((sum, w) => sum + w.metrics.cost, 0);
      const averageLatency = totalWorkflows > 0
        ? timeframeWorkflows.reduce((sum, w) => sum + w.metrics.duration, 0) / totalWorkflows
        : 0;

      // Calculate service usage
      const serviceUsage: Record<string, number> = {};
      timeframeWorkflows.forEach(workflow => {
        workflow.metrics.servicesUsed.forEach(service => {
          serviceUsage[service] = (serviceUsage[service] || 0) + 1;
        });
      });

      // Generate trends (simplified)
      const trends = {
        costOverTime: timeframeWorkflows.map(w => ({
          timestamp: w.timestamp,
          cost: w.metrics.cost
        })),
        performanceOverTime: timeframeWorkflows.map(w => ({
          timestamp: w.timestamp,
          latency: w.metrics.duration,
          successRate: w.metrics.successRate
        })),
        serviceUsageOverTime: timeframeWorkflows.map(w => ({
          timestamp: w.timestamp,
          services: w.metrics.servicesUsed.reduce((acc, service) => {
            acc[service] = (acc[service] || 0) + 1;
            return acc;
          }, {} as Record<string, number>)
        }))
      };

      // Generate recommendations
      const recommendations = this.generateRecommendations({
        totalWorkflows,
        successfulWorkflows,
        failedWorkflows,
        totalCost,
        averageLatency,
        serviceUsage
      });

      return {
        timeframe,
        summary: {
          totalWorkflows,
          successfulWorkflows,
          failedWorkflows,
          totalCost,
          averageLatency,
          serviceUsage
        },
        trends,
        recommendations
      };

    } catch (error) {
      console.error('Failed to generate enterprise analytics:', error);
      throw new Error(`Analytics generation failed: ${(error as Error).message}`);
    }
  }

  /**
   * Get cutoff time for timeframe
   */
  private getCutoffTime(timeframe: string): Date {
    const now = new Date();
    switch (timeframe) {
      case 'hour':
        return new Date(now.getTime() - 60 * 60 * 1000);
      case 'day':
        return new Date(now.getTime() - 24 * 60 * 60 * 1000);
      case 'week':
        return new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);
      case 'month':
        return new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);
      default:
        return new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);
    }
  }

  /**
   * Generate recommendations based on analytics
   */
  private generateRecommendations(data: any): string[] {
    const recommendations: string[] = [];

    if (data.failedWorkflows > data.totalWorkflows * 0.1) {
      recommendations.push('High failure rate detected. Review error patterns and improve error handling.');
    }

    if (data.averageLatency > 5000) {
      recommendations.push('Average latency is high. Consider optimizing service configurations or using faster models.');
    }

    if (data.totalCost > 100) {
      recommendations.push('High operational costs detected. Review cost optimization strategies and service usage.');
    }

    const mostUsedService = Object.entries(data.serviceUsage)
      .sort(([, a], [, b]) => (b as number) - (a as number))[0];

    if (mostUsedService) {
      recommendations.push(`Consider optimizing ${mostUsedService[0]} service usage for better performance.`);
    }

    if (recommendations.length === 0) {
      recommendations.push('All systems operating optimally. Continue monitoring for any emerging issues.');
    }

    return recommendations;
  }

  /**
   * Get active workflows
   */
  getActiveWorkflows(): EnterpriseWorkflowResult[] {
    return Array.from(this.activeWorkflows.values());
  }

  /**
   * Get workflow history
   */
  getWorkflowHistory(limit: number = 50): EnterpriseWorkflowResult[] {
    return this.workflowHistory
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime())
      .slice(0, limit);
  }

  /**
   * Clean up old workflow history
   */
  cleanup(olderThanDays: number = 30): number {
    const cutoffTime = new Date(Date.now() - (olderThanDays * 24 * 60 * 60 * 1000));
    const initialLength = this.workflowHistory.length;

    this.workflowHistory = this.workflowHistory.filter(workflow => workflow.timestamp >= cutoffTime);

    const cleanedCount = initialLength - this.workflowHistory.length;
    console.log(`Cleaned up ${cleanedCount} old enterprise workflows`);

    return cleanedCount;
  }
}

// Export singleton instance
export const enterpriseOrchestrator = new EnterpriseOrchestrator();
